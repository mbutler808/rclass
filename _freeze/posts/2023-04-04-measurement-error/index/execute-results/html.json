{
  "hash": "4e93e8f3cb943fea281161994d474375",
  "result": {
    "markdown": "---\ntitle: \"Measurement Error\"\nauthor:\n  - name: Marguerite Butler\n    url: https://butlerlab.org\n    affiliation: School of Life Sciences, University of Hawaii\n    affiliation_url: https://manoa.hawaii.edu/lifesciences/\ndescription: \"Getting started with some issues in morphometrics\"\ndate: 2023-03-30\ncategories: [module 6, week 12, control structures, if else, (do) while, programming]\nbibliography: refs.bib\n---\n\n\n### Acknowledgements\n\nMaterial for this lecture was borrowed and adopted from\n\n- <https://www.r-bloggers.com/2015/04/tips-tricks-8-examining-replicate-error/>\n\n# Learning objectives\n\n::: callout-note\n# Learning objectives\n\n**At the end of this lesson you will:**\n\n-   Be able to estimate measurement error and repeatability\n-   \n:::\n\n# Overview\n\n# Measurement Error and Repeatability\n\nMorphometrics is all about assessing variability, within and between individuals. One of those sources of variability is measurement error. \n\nMeasurement Error (ME) itself comes from many potential sources:\n\n-  the measurement device (precision)\n-  definition of the measure\n-  quality of the measured material\n-  the measurer\n-  the environment of the measurer (hopefully small!)\n-  measurement protocol\n\nWe try to minimize ME so that we can reveal the underlying patterns we are interested in, but there will always be some ME. So it is important to quantify at least once at the beginning of the study. \n\n## Protocol for assessing ME\n\nThe percentage of measurement error is defined as the within-group component of variance divided by the total (within + betwee group) variance [@Claude:2008]:\n\n$$\n\\%ME = \\frac{s^{2}_{within}}{s^{2}_{within} + s^{2}_{among}} \\times 100\n$$\n\nWe can get the componets of variance $s^{2}$ from the mean squares ($MSS$) of an ANOVA considering the individual (as a factor) source of variation. Individual here represents the within-group variation. The among and within variance can be estimated from the mean sum of squares and $m$ the number of repeated measurements:\n\n$$\ns^{2}_{among} = \\frac{MSS_{among} - MSS_{within}}{m} \n$$\n\nand \n\n$$\ns^{2}_{within} = MSS_{within} \n$$\n\n## Example\n\nSuppose we are taking photographs of specimens, and then collecting landmark data from the photos. This is a pretty typical data collection pipeline. \n\nBecause we are taking 2D photos from 3D objects, one potential issue is whether the shape variation we obtain is real, or whether it is introduced by placing either the object or the camera at slightly different angles. \n\nAnother potential issue is whether we are placing the digitized landmarks in exactly the same place.  \n\nThere may be additional issues as well - for example some small ambiguity on the physical object, or the material or photos may be of different quality. \n\n### Plan your data management\n\nI always recommend storing your metadata in the filenames. That way you never lose the information. \n\n__Photo files:__  A good strategy for data management is to label the photo files:\n              `id_picture_replicate.jpg`\n\nWhere:\n-  __id__ refers to the specimen, \n-  __picture__ the replicate photo (photo1 or photo2), and \n-  __replicate__ the replicate landmark coordinates (rep1 or rep2). \n\nWe can parse the metadata from the filenames by code such as:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiles <- list.files()  # to read the file names from the current drectory\nfiles <- files <- c(\"id1_photo1_rep1.jpg\", \n                    \"id1_photo1_rep2.jpg\", \n                    \"id1_photo2_rep1.jpg\", \n                    \"id1_photo2_rep2.jpg\")  # made up example to practice \n\n# Collect metadata, approach 1 - substr\nmeta <- strsplit(files, \"_|\\\\.\")  # metadata. split filenames by _ or . \n                                  # Need to use \\\\ to escape the .\nid <- sapply(meta, \"[[\", 1)\nphoto <- sapply(meta, \"[[\", 2)\nrep <- sapply(meta, \"[[\", 3)\n\n# Collect metadata approach 2 - sub\n# using sub and regular expressions to select (string1)_(string2)_(string3)\n# also ignoring the final .jpg, where . is escaped by \\\\\n\nid <- sub(\"^([a-zA-Z0-9]+)_([a-zA-Z0-9]+)_([a-zA-Z0-9]+)(\\\\.jpg)\", \"\\\\1\", files)\nphoto <- sub(\"^([a-zA-Z0-9]+)_([a-zA-Z0-9]+)_([a-zA-Z0-9]+)(\\\\.jpg)\", \"\\\\2\", files)\nrep <- sub(\"^([a-zA-Z0-9]+)_([a-zA-Z0-9]+)_([a-zA-Z0-9]+)(\\\\.jpg)\", \"\\\\3\", files)\n```\n:::\n\n\nWe can use these vectors along with the coordinates to test for measurement error with ANOVA. \n\n### Statistical methods for Measurement Error:\n\nWe will assess measurement error at two levels, photography error  and digitizing error: \n\n__Photography error:__ Take __two sets of photos__, each time placing the object in front of the camera and positioning the specimen. (I.e., the entire process to give us a good estimate of photo capture error)\n\n__Landmark digitizing error:__ Collect landmarks twice, ideally in different sessions on different days or weeks. \n\n__Data:__  In this example we will have 4 sets of landmark data for each specimen, 2 photos x 2 digitizing replicates, allowing assessment of error associated with the digitization as well as error in capturing the shapes via the photographs. \n\n__Model:__ We will use a [nested ANOVA](http://www.biostathandbook.com/nestedanova.html) to estimate repeatability and (measurement error) of the landmarks, to try to separate the variation introduced by the digitization process, apart from the other sources of variation. \n\n\n### Analyze with ANOVA: \n\nNested ANOVA indicates that we have a nested structure of replicates within groups (i.e., `rep1` of `photo1` has nothing to do with `rep1` of `photo2`. `rep` is nested within `photo`. \n\nIn R we specify a nested model forumula [using :](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html) in the model term (to indicate interaction terms only with no main effect): \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm.fit <- lm(coords ~ id:photo:rep)\naov(lm.fit)\n```\n:::\n\n__Data and model term objects:__\n-  __coords__ is the data object (a vector or array)\n-  __id__ is a vector containing labels for each specimen\n-  __photo__ is a vector (photo is 1 or 2)\n-  __rep__ is a vector (digitizing replicate 1 or 2)\n\n\nLook at the values of the Mean Squares (MS) column in the ANOVA table. Compare the value for `id:photo` and `id:photo:rep` with `id`. \n\nTo calculate the __repeatability__ of our digitizing ability, we subtract the __MS__ of the __rep__ term from the __individual__ term and divide by __two__ (because we have two replicates):\n__(MS(id) – MS(ind:photo:rep))/2__\n\nThen we calculate the ratio of this value to the total MS:\n__((MS(id) – MS(id:photo:rep))/2 ) / (MS(id)+MS(id:photo)+MS(id:photo:rep))__ \n\nThe result is the __repeatability__, which in good circumstances is somewhere above 0.95; and thus 5% __measurement error__.\n\n\n### Simulated example:\n\nMeasure 5 specimens (single measurement). \nTake two photos of each specimen, digitized twice (once in each of two sessions on different days).  How repeatable are the measurements?  \n\nSimulate the data:  \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrue_m <- rnorm(10,20,3)  # true values for 10 specimens\np1 <- true_m + rnorm(10,0,.1)\np2 <- true_m + rnorm(10,0,.1)\n\np1m1 <- true_m + p1 + rnorm(10,0,.05) # photo 1 measurements set 1\np1m2 <- true_m + p1 + rnorm(10,0,.05)\np2m1 <- true_m + p2 + rnorm(10,0,.05) # photo 2 measurements set 1\np2m2 <- true_m + p2 + rnorm(10,0,.05)\n\nid <- as.factor(rep(1:10, times=4))\nphoto <- as.factor(rep(rep(1:2, each=10), times=2))\nrep <- gl(2, 20)\ntotal_m <- c(p1m1, p2m1, p1m2, p2m2)\ncbind(id, total_m, photo, rep)  # the data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      id  total_m photo rep\n [1,]  1 35.39748     1   1\n [2,]  2 37.30217     1   1\n [3,]  3 46.00803     1   1\n [4,]  4 53.12722     1   1\n [5,]  5 40.37326     1   1\n [6,]  6 48.54945     1   1\n [7,]  7 46.50575     1   1\n [8,]  8 31.60134     1   1\n [9,]  9 37.17727     1   1\n[10,] 10 40.36666     1   1\n[11,]  1 35.62908     2   1\n[12,]  2 37.36254     2   1\n[13,]  3 45.91070     2   1\n[14,]  4 53.45772     2   1\n[15,]  5 40.71606     2   1\n[16,]  6 48.55707     2   1\n[17,]  7 46.20721     2   1\n[18,]  8 31.78617     2   1\n[19,]  9 37.04354     2   1\n[20,] 10 40.20327     2   1\n[21,]  1 35.42613     1   2\n[22,]  2 37.24099     1   2\n[23,]  3 45.98112     1   2\n[24,]  4 53.26413     1   2\n[25,]  5 40.41467     1   2\n[26,]  6 48.48049     1   2\n[27,]  7 46.49152     1   2\n[28,]  8 31.58885     1   2\n[29,]  9 37.16410     1   2\n[30,] 10 40.30348     1   2\n[31,]  1 35.63525     2   2\n[32,]  2 37.45346     2   2\n[33,]  3 45.87819     2   2\n[34,]  4 53.38298     2   2\n[35,]  5 40.66658     2   2\n[36,]  6 48.54141     2   2\n[37,]  7 46.33105     2   2\n[38,]  8 31.82383     2   2\n[39,]  9 37.04875     2   2\n[40,] 10 40.21751     2   2\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(aov(lm ( total_m ~ id:photo:rep)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Df Sum Sq Mean Sq\nid:photo:rep 39   1612   41.34\n```\n:::\n\n```{.r .cell-code}\nmsi <- summary(aov(lm ( total_m ~ id)))[[1]][1,3]\nmsip <- summary(aov(lm ( total_m ~ id:photo)))[[1]][1,3]\nmsipr <- summary(aov(lm ( total_m ~ id:photo:rep)))[[1]][1,3]\n```\n:::\n\n\nTo calculate the repeatability of our digitizing ability, we subtract the MS of the id:photo:rep term from the id term and divide by two (because we have two replicates):\n\n(MS(id) – MS(id:photo:rep))/2 \n\nThen we calculate the ratio of this value to the total MS:\n\n((MS(id) – MS(id:photo:rep))/2 ) / (MS(id)+MS(id:photo)+MS(id:photo:rep)) \n\nThe result is a value, which in good circumstances is somewhere above 0.95; a repeatability of 0.95 and thus 5% error.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n((msi - msipr)/2) / (msi+msip+msipr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2256166\n```\n:::\n:::\n\nAnd the percent measurement error is represented by `pME`.  As a rough rule of thumb we want this to be less than 5%.  If it is very high, we either want to practice more, or take multiple measurements of each variable and average them. \n\n\nAlternatively, if we were interested in inter-observer error vs. repeatability within observer, we could take one photograph and have it measured by two different people, each person taking two sets of measurements (preferably in different sessions). \n\n\n\n\nThe same can be done for the photos (ind:photo) but of course remember digitizing error is also in this term. This post is inspired by Chapter 9 of the Green Book, which I strongly recommend reading.\n\nRemember, all this can be done by accessing the parts of the ANOVA table using regular R indexing. Dump the output of procD.lm into an object e.g. called res then res[,3] will be the MS values.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
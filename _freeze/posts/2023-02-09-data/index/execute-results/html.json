{
  "hash": "48de07e0d4e6870e7a0128f911b93a34",
  "result": {
    "markdown": "---\ntitle: Types of Data\nauthor:\n  - name: Marguerite Butler\n    url: https://butlerlab.org\n    affiliation: School of Life Sciences, University of Hawaii\n    affiliation_url: https://manoa.hawaii.edu/lifesciences/\ndescription: \"All about data and how it is represented in R\"\nfig_caption: yes\ndate: 2023-02-09\ncategories: [module 2, week 4, data, data structures, objects ]\n---\n\n\n<!-- Add interesting quote -->\n\n<!-- # Pre-lecture materials -->\n\n<!-- R emoji aliases:  https://gist.github.com/rxaviers/7360908 -->\n✏️\n\n# Overview \n\nWe will discuss different types of data, how they are represented in R, and how data type influences the types of data analyses we may employ. \n\n# Pre-lecture materials\n\n### Watch\n\n::: callout-note\n# Watch \n**Before class, you can prepare by watching:**\n\n\n{{< video https://youtu.be/wzPRpyoNaa8 start=\"350\" >}}\n\n\n:::\n\n## Acknowledgements\n\nMaterial for this lecture was borrowed and adopted from\n\n- <https://andreashandel.github.io/MADAcourse/Data_Types.html> \n- <https://r-coder.com/data-types-r/#Raw_data_type_in_R>\n- <https://www.stat.auckland.ac.nz/~paul/ItDT/HTML/node76.html>\n# Learning objectives\n\n::: callout-note\n# Learning objectives\n\n**At the end of this lesson you will:**\n\n* Understand different types of data and how they are represented computationally \n* Understand that different data types require different analysis approaches\n* Recognize different base data types in R and know how to work with them\n* Know about the base data structures in R and how to make them do what you want\n:::\n\n\n\n# What is data anyway?\n\nMerriam Webster defines **data** as *factual information (such as **measurements** or **statistics**) used as a basis for **reasoning**, **discussion**, or **calculation**.*\n\nFrom a practicing scientistsʻ point of view, data is anything **measureable** or **scorable** that could provide **information** regarding a phenomenon of interest. \n\nIdeally, data:   \n\n*  are **repeatable** (at least within statistical error).  \n*  contain more **signal** than **noise**.  \n\nFor example, if we are studying how morphology changes with body size, we could take measurements such as *body length*, *head length*, *arm length*, and *leg length* on a sample of *individuals*.  These measurements would provide linear, **continuous data** that would inform our study of size and scaling. If we also expected males and females to differ, then *sex* would be a **categorical variable**. \n\n-  It is important to *define the variables* so that the measurements are *repeatable* by other scientists collecting data on the same or similar samples.  \n-  The *variables* chosen are expected to be related to the phenomenon of interest (here, scaling).  \n-  The *individuals* are replicates from the same sample population, meaning that they should be equally embody or be influenced by the phenomenon we are studying. In other words, they form a homogenous sample.  In the example of sexual dimorphism, we potentially have different groups within our sample. This can be taken account of in analyses using our *categorical grouping variable* *sex*. \n \nData have many forms such as images, sound, video, text, or any combination. Today we also have access to large volume datastreams from remote sensing, social media, or from all the various -omics. The kind of data, and how messy it is, determines the amount of processing that needs to be done before analysis. \n\nAt some point your data will most likely be arranged into spreadsheets, with observations as rows and variables as columns. **In this course, we will focus on the data source that you are most likely to encounter in your analyses, the \"(messy) spreadsheet\" type, containing bits of information collected on individuals.** Please do feel free to play around with other data types on your own, e.g. for your course project.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Weʻve all been here. Source: timoelliott.com](../../images/i-have-data_3.jpeg){#fig-havedata fig-align='center' fig-alt='A cartoon showing two people arguing at a table, and a third person, the data analyst is at his laptop. He is smiling and says *When you two have finished arguing your opinions, I actually have data*.' width=80%}\n:::\n:::\n\n[Source: timoelliott.com](https://timoelliott.com/blog/cartoons/analytics-cartoons)\n\n\n\n\n# Types of Variables\n\nVariables are the conceptual elements of the data. Variables are typically categorized by the nature of how they can vary (i.e., quantitative, qualitative, ordinal), because these differences dictate different analytical approaches and statistical methods. \n\n__Quantitative:__ This data type, also called _metric_ data, represents variation in magnitude and generally allows one to do certain mathematical operations, e.g., subtraction or addition. The most common variations include:\n\n  * *__Continuous__*: Can take on any numerical value. Examples include mass, length, distance, age, etc.\n  * *__Discrete__*: Can only take countable (integer) values, e.g., the number of offspring an indivdiual produces. \n  * *__Fraction/Proportion__*: A continuous ratio of two values, with the numerator being a part to the whole which is represented by the demoninator. Thus these variables take on values between 0 and 1.\n  * *__Ratios__*:  A continuous ratio of any two values. Data measured on a ratio scale have all the properties of continuous data. \n\n__Qualitative:__ Generally speaking, qualitative data indicate *categories* which have no intrinsic numeric value or natural order. Therefore it would not make sense to apply arithmetic to qualitative data such as color, sex, or family group, etc. You may see the term *nominal* (definition: \"pertaining to names\") data applied to categorial data in the statistical literature. Major types of __qualitative__ data include:\n\n* *__Categorical__*: e.g., flower color, continent of origin, social status, disease state, etc.\n* *__Descriptive__*: e.g., free text data from field observations.\n\n  \n__Ordinal:__ Related to categorical data, this type differs in that they can be ranked, at least qualitatively. \n\nFor example, while body condition may be a qualitative assessment, \"obese\"  clearly indicates greater fat stores than \"well-conditioned\", which is greater than \"emaciated\". Thus, ordinal data fall between being strictly quantitative or strictly qualitative. In some cases, if there are numerous categories, you can begin to think of them as approaching continuous data, although one important difference is that there is no clear numerical value that you can assign to the different categories (i.e., it is unclear whether the difference between obese and well-conditioned is the same as the difference between well-conditioned and emaciated). It may make sense to apply rank order statistics to ordinal data, but it would not make sense to add, subtract, or multiply these categories. \n\n\n\n\n\n# Analysis approaches and their relationship to data\n\nIt may be obvious that data type will dictate the types of analyses one can do. It might be less obvious that the __question of interest__ and whether there is a _quantitative or ordinal outcome_ also drive our analyitical approach. \n\n\n### When we want to know the strength of the quantitative relationship \n\nMethods for __quantitative responses__ (or outcomes) that address questions such as \"_how much does leg length increase with body size?_\"? In other words, \"_how much does variable Y change with each increment of change in variable X_?\" These are usually referred to as __regression approaches__. \n\nThere are many subtypes of regression such as linear regression for continuous outcomes, and Poisson regression for discrete outcomes. \n\n-  __*Linear regression*__ predicts a continuous response, such as body size.\n-  __*Poisson regression*__ predicts a count or discrete response, such as population size.  \n\nBoth types of regression can be based independent variables that are continuous, discrete, or categorical (or some combination). They differ in the underlying distribution of the modeled response variable, often a normal distribution for linear regression, and a Poisson distribution for the Poisson regression. \n\n\n### When we want to know about grouping \n\nMethods that recover __categorical responses__, in other words, categorizing observations based on the analysis of data, are usually referred to as __classification approaches.__ These methods are useful for looking for order in nature, such as whether different species can be grouped into \"ecomorphs\" based on their morphology, or to predict the type of behavioral response (e.g., \"attack\" or \"flee\") based on responses to different stimuli. \n\nIt is possible to obtain an ordinal response as well, using [__ordinal regression__](https://en.wikipedia.org/wiki/Ordinal_regression). Alternatively, the the response can be treated as unordered categorical or as continuous (depending on how you code them, i.e., in R as a factor or numeric). \n\nThere are no hard and fast rules regarding when it is appropriate to treat an ordinal variable as fully quantitative. It should, however, at least be explained or justified. You can always treat it as categorical, but then you lose some information on the ranking of the variable.  \n\nTo add to the confusion, these classification methods are often based on regression, with the decision to classify based on one category or another dependent on comparing distances or probabilities based on regression results.[^1] \n\nRecently, there has been a lot of interest in AI and machine learning. This is often just a fancy way of renaming __*discriminant function analysis*__ and __*cluster analysis*__. When you see _supervised_ learning in the literature, it refers to cases when we have the categories predefined, and often we have a training dataset with data on individuals of each category to use to train the classification algorithm before we use it to predict grouping (i.e., *discriminant function analysis*). When we donʻt have the categories *a priori*, and the algorithms determine the categories and their number, these analysis methods are usually referred to as _clustering approaches_ and are also called _unsupervised_ learning methods. \n\nWe will return to and apply some of those methods later in the course.\n\n[^1]: For example, logistic regression (a regression to predict a binary [yes/no] outcome) is used for classification. The underlying model predicts a quantitative outcome (a value between 0 and 1 usually interpreted as a probability), which is then binned to make categorical predictions.\n\n\n\n# Data types in R\n\nNow that we have a basic understanding of the conceptual landscape of data, letʻs breifly discuss how these different types of data are represented in and handled by R. \n\nIf you would like a gentle video walk through/demonstration of data types, now would be a good time to check out the _Types_ section of the RStudio [programming basic primer](https://rstudio.cloud/learn/primers/1.2). For more details and examples see [chapter 3 of IDS](https://rafalab.github.io/dsbook/r-basics.html).\n\n\n## Basic data types\n\n:::{.callout-note}\n## R has six basic (atomic) types of data:\n\n| Atomic Type | Short Description |\n|---------|:-----|\n| __string__  (or character)    | text   |\n| __integer__ | countable numbers   |\n| __real__ | real numbers   |\n| __logical__ | TRUE or FALSE |\n| __complex__ | numbers with imaginary component |\n| __raw__ | raw bytes |\n_**All other data types are derived from the atomic types**_\n:::\n\nhttps://r-coder.com/data-types-r/#Raw_data_type_in_R\n\n\n__String/character:__ Character values are alphanumeric values (plus whitespace, punctuation, etc.). A string is a collection of characters, in other words \"text\". \n\n-  strings can be pasted together using the `paste()` function. \n-  R has powerful tools for __string manipulation__, including searching, replacing, and customized partial matching (with or without replacement) using __wildcards__ and perl-like [__regular expressions__ (or __regex__)](https://github.com/rstudio/cheatsheets/blob/master/regex.pdf) using base functions such as \n    *  `grep()`\n    *  `sub()`\n    *  `gsub()`\n    *  `substr()`\n-  There are also packages specific for string manipulation including the [`stringr` package](https://stringr.tidyverse.org/) which is part of the tidyverse.\n\nIt is very likely that you will need to work with strings at some point during a data analysis, even if it is only to find specific values, clean up variable names, etc. \n\nThese problems can be quite the headache! But instead of editing them by hand and possibly making an error, it is better to do this with code. It also makes it easier to keep a record of the original data and all of the changes made to it, improving the reproducibility of your analysis. \n\nThere is a learning curve to using these tools, especially **regex** syntax, but they are very powerful and well worth your time. \n\n:::{.callout-note}\n## Good sources for practice manipulating strings:\n\n- For beginners: Review [the _Strings_ chapter (14) of R4DS](https://r4ds.had.co.nz/strings.html), and do the exercises.\n- [The _string processing_ chapter (25) of IDS](https://rafalab.github.io/dsbook/string-processing.html) \n- [the _Character Vectors_ chapter in the STAT 545 book](https://stat545.com/character-vectors.html) by [Jenny Bryan](https://jennybryan.org/)  \n\n**Decide which one is right for your level and work through some examples. I think youʻll agree that it is worth your time.**\n:::\n\n\n__Numeric (double or integer):__ Variables of type `numeric` in R are either integers or double precision (representing real numbers). \n\n-  Integers and real values are different, but in practice most R users donʻt pay attention to this distinction. Integer values tend to be coerced (converted) to real values if any mathematical operations are done to them. \n-  If an integer is explicity needed, you can create them using functions such as `as.integer()`.\n-  Note that when you type an integer value, e.g. `x <- 2`, into R, this is considered numeric by default. \n-  If you want to make sure a value is treated as integer, add an `L`, e.g. `x <- 2L`.\n\n\n\n__Logical:__ Logical variables are binary and can take on only two values, `TRUE` or `FALSE` (which are *reserved words* that only take on these meanings in R). \n\n- In R, logical values are interpreted as 1 for `TRUE` and 0 for `FALSE`. \n- R also understands `T`, `True`, and `true` for `TRUE`, and the corresponding representations for `FALSE`.\n- Importantly, logical comparisons are used for __indexing__. You will use logical comparisons when cleaning and checking your data, or running analyses, e.g., if you want to see if your variable `x` is greater than 5, then the R command `x > 5` will return either TRUE or FALSE, based on the value of `x`. \n- *Note: reserved words are understood as constants and should not be \"quoted\"*.\n\n## Derived data types\n\nR also allows derived data types called **classes** that are built up from atomic data types. There are R base classes as well as new classes that can be defined as needed by programmers (maybe you?). \n\n__Factors:__ Are Rʻs class for categorical variables. \n\n-  __Factors__ have __names__ and __values__. \n-  For example, a __size__ factor may have `names` (or `levels`) of `small`, `medium`. and `large` with values 0,1,2.  Here, the values simply indicate the different categories, with the names being the human-friendly labels for the values.  \n-  Factors can be ordered/ordinal or not. \n  +  Factors could be numeric values, e.g., the number of offspring. \n  +  Or it could be a factor coding for 3 types of habitat (unordered), \n  +  Or 3 levels of life history stage (ordered). \n  +  An excellent package to work with factors is the [`forcats` package](https://forcats.tidyverse.org/). \n\nFor more about factors, work through the [_Factors_ chapter of R4DS](https://r4ds.had.co.nz/factors.html), and do the exercises. \n\n\n__Date/time:__ Dates in base R are of the class `Date` (and are called `POSIX` variables). The [`lubridate` package](https://lubridate.tidyverse.org/) is a tidyverse package to work with dates, which many people find easier. There are other packages as well. \n\nAdditional resources are the [_Dates and times_ chapter of R4DS](https://r4ds.had.co.nz/dates-and-times.html) and the [_Parsing Dates and Times_ chapter of IDS](https://rafalab.github.io/dsbook/parsing-dates-and-times.html). \n\n\n__Programmer-defined classes__ Many packages define their own classes. For example class `phylo` is used to represent phylogenetic trees in the `ape` package. \n\n### There are several functions that can show you the data type of an R object \n\nsuch as `typeof()`, `mode()`, `storage.mode()`, `class()` and `str()`.\n\n\n\n## Data structures in R\n\nData in R are stored in data structures called **objects**. \n\n__Vectors:__ vectors are the simplest object, a collection of data elements in a single sequence. \n\n-  One way to create vectors is with the `concatenate` command, `c()`.  \n-  `1:3` is shorthand for a numeric sequence `=c(1,2,3)`  \n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(3,12,5)\ny <- 1:3\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  3 12  5\n```\n:::\n\n```{.r .cell-code}\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2 3\n```\n:::\n:::\n\n\n-  **A single vector can contain only one type** (e.g., all characters or all numeric). \n  +  If you try to mix and match, everything will default to the lowest common denominator, typically a character (anything can be a character). \n\n\n::: {.cell}\n\n```{.r .cell-code}\nx1 <- c(3, 1, \"dog\")\nclass(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"numeric\"\n```\n:::\n\n```{.r .cell-code}\nclass(x1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"character\"\n```\n:::\n\n```{.r .cell-code}\nx1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"3\"   \"1\"   \"dog\"\n```\n:::\n:::\n\nWhat happened?\n\n\n__Matrices:__ A matrix is a rectangular collection of data elements in rows and columns. \n\n-  A matrix can contain only one type. \n-  Internally, R stores matrices as a long vector, keeping track of where the columm breaks are.\n-  Matrices are really important for the matrix math used to solve many statistical models. \n\n\n\n__Data frames:__ A data frame is a rectangular data structure that is designed to store records of individual subjects. \n\n-  A data frame has rows and columns.\n-  Columns are allowed to be of different data types (for example, \"character\" for the subject names and \"numeric\" for measured variables for each subject, and \"factors\" for categories such as sex, etc.).\n-  Internally, data frames are stored as a list of vectors, one for each column. This allows each column to have a different type. \n-  Each columm must have the same number of elements or rows, i.e., it must be rectangular.\n-  Typically, the columms of data frames have names corresponding to variable names.\n\n\n__Lists:__ Lists do not have to be rectangular and are the most flexible data type in R. A list is a vector possibly composed of different structures and of varying length (this is the only type where that is allowed!).\n> \n-  Lists are commonly used for model fits in statistical functions. For example, you may want to store the model (an expression), the input data (a dataframe), the output coefficients (a vector), \n-  R has many powerful functions that operate on lists. \n\nOther types of data structures exist; they are often introduced by specific R packages. An important one to know is the `tibble` which is a type of data frame used in the `tidyverse`. It is similar, but not exactly like a data frame. You can read more about `tibbles` [on its package website](https://tibble.tidyverse.org/) and in [R4DS chapter 10](https://r4ds.had.co.nz/tibbles.html).\n\n\n\n## Other derived data types\n\n__Timeseries:__  A very useful set of tools for  times-series analysis in R is the set of packages called [the tidyverts](https://tidyverts.org/). CRAN also has a [Task View for _Time Series Analysis_.](https://cran.r-project.org/web/views/TimeSeries.html) (A _Task View_ on CRAN is a site that tries to combine and summarize various R packages for a specific topic). Another task view that deals with longitudinal/time-series data is the [_Survival Analysis_ Task View](https://cran.r-project.org/web/views/Survival.html).\n\n\n__Omics:__ The [bioconductor](https://www.bioconductor.org/) website is your source for (almost) all tools and resources related to omics-type data analyses in R.\n\n\n__Text:__  Working with and analyzing larger sections of text is different from the simple string manipulation discussed above. These days, analysis of text often goes by the term _natural language processing_. Such text analysis will continue to increase in importance, given the increasing data streams of that type. If you are interested in doing full analyses of text data, the [`tidytext` R package](https://juliasilge.github.io/tidytext/) and the [Text mining with R book](https://www.tidytextmining.com/) are great resources. A short introduction to this topic is [The _text mining_ chapter (27) of IDS.](https://rafalab.github.io/dsbook/text-mining.html) \n\n\n__Images:__ Images are generally converted into multiple matrices of values for different pixels of an image. For instance, one could divide an image into a 100x100 grid of pixels, and assign each pixel a RGB values and intensity. That means one would have 4 matrices of numeric values, each of size 100x100. One would then perform operations on those values. We won't do anything with images here, there are some R packages for analyzing image data.\n\n\n\n__Videos:__ Are a time-series of images. Analysis of videos therefore has an extra layer of complexity. \n\n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}